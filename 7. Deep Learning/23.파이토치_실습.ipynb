{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32ce4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchinfo import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3923cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b596f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU 혹은 GPU  장치 확인해보기\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c9eef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf7dd7",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84851da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0.5, 표준편차가 1.0이 되도록 데이터의 분포를 정규화\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4472a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(\n",
    "    root = \"./data/\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = mnist_transform)\n",
    "testset = datasets.MNIST(\n",
    "    root = \"./data/\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = mnist_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bf1502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29adb264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c4f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 데이터로더에 전달\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size = 100)\n",
    "test_loader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fdbec8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "\n",
    "for i in range(1, columns * rows + 1):\n",
    "    img_xy = np.random.randint(len(trainset))\n",
    "    img = trainset[img_xy][0][0, :, :]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    \n",
    "    plt.axis (\"off\")\n",
    "    plt.imshow(img, cmap = \"gray\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0404c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# train, test 데이터 크기 확인\n",
    "print(len(trainset[1][0][0]))\n",
    "print(len(testset[1][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24689ce5",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193e1e6",
   "metadata": {},
   "source": [
    "### 합성곱 신경망 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25a8ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels=32, kernel_size=5, padding = 2),\n",
    "            # (28 - 5 + 2 * 2)/1 + 1 =28\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            # 28 / 2 = 14\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding = 2),\n",
    "            # (14 - 5 + 2 * 2)/1 + 1 = 14\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2)\n",
    "            # 14 / 2 = 7\n",
    "        )\n",
    "        \n",
    "        # 전결합층\n",
    "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=1024) \n",
    "        # out_features = 유닛 수\n",
    "        self.drop = nn.Dropout2d(0.3)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=10)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9db56ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Mnist                                    --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       832\n",
       "│    └─BatchNorm2d: 2-2                  64\n",
       "│    └─ReLU: 2-3                         --\n",
       "│    └─MaxPool2d: 2-4                    --\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Conv2d: 2-5                       51,264\n",
       "│    └─BatchNorm2d: 2-6                  128\n",
       "│    └─ReLU: 2-7                         --\n",
       "│    └─MaxPool2d: 2-8                    --\n",
       "├─Linear: 1-3                            3,212,288\n",
       "├─Dropout2d: 1-4                         --\n",
       "├─Linear: 1-5                            262,400\n",
       "├─Linear: 1-6                            2,570\n",
       "=================================================================\n",
       "Total params: 3,529,546\n",
       "Trainable params: 3,529,546\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Mnist()\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35dcf479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
      "  (drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 합성곱 신경망 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model = Mnist() # 위에서 만든 class를 객체화\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # adam\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765f034",
   "metadata": {},
   "source": [
    "# 모델 학습2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0157dda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.1338394731283188, Accucacy: 96.27999877929688%\n",
      "Iteration: 1000, Loss: 0.21552427113056183, Accucacy: 97.7699966430664%\n",
      "Iteration: 1500, Loss: 0.06444184482097626, Accucacy: 98.80999755859375%\n",
      "Iteration: 2000, Loss: 0.05918227508664131, Accucacy: 98.58000183105469%\n",
      "Iteration: 2500, Loss: 0.013481019996106625, Accucacy: 98.54000091552734%\n",
      "Iteration: 3000, Loss: 0.22456355392932892, Accucacy: 98.83999633789062%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        # 모델이 데이터를 처리하기 위해서는 모델과 데이터가 동일한 장치에 있어야 함\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels) # autograd = 자동미분계산\n",
    "        # Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\n",
    "        # 자동 미분에 대한 값을 저장\n",
    "        \n",
    "        # 해당 과정은 파이토치에서 항상 고정\n",
    "        outputs = model(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad() # optimizer가 실행되기 전에 초기화 시킴\n",
    "        loss.backward() # 오차 역전파\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50): # = 50으로 나누어 떨어졌을 때\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels, in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device) # (출력값, 인덱스)[1]\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels) # 전체 정답값 갯수 total에 담기\n",
    "                \n",
    "            accuracy = correct * 100 / total # 정확도 계산\n",
    "            loss_list.append(loss.data) # loss = criterion(outputs, labels)\n",
    "            # 손실값을 50 steps 마다 기록을 남길 것\n",
    "            iteration_list.append(count) # step = iteration\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f\"Iteration: {count}, Loss: {loss.data}, Accucacy: {accuracy}%\")\n",
    "            # 로그 뿌리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87697251",
   "metadata": {},
   "source": [
    "# 모델 생성2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "966ad901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels=32, kernel_size=3),\n",
    "            # (28 - 3 + 2 * 0)/1 + 1 =26\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            # 26 / 2 = 13\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            # (13 - 3 + 2 * 0)/1 + 1 = 11\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2)\n",
    "            # 11 / 2 = 5.5\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(in_features=64 * 7 * 7, out_features = 10),\n",
    "            nn.ReLU(inplace = True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "532c13f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Mnist2                                   --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Conv2d: 2-1                       320\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─MaxPool2d: 2-3                    --\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Conv2d: 2-4                       18,496\n",
       "│    └─ReLU: 2-5                         --\n",
       "│    └─MaxPool2d: 2-6                    --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-7                       31,370\n",
       "│    └─ReLU: 2-8                         --\n",
       "=================================================================\n",
       "Total params: 50,186\n",
       "Trainable params: 50,186\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Mnist2()\n",
    "\n",
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d9cf5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist2(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 합성곱 신경망 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model2 = Mnist2() # 위에서 만든 class를 객체화\n",
    "model2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 손실 함수\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr = learning_rate) # adam\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bac216",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b30ea9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 2.8679375648498535, Accucacy: 12.630000114440918%\n",
      "Iteration: 1000, Loss: 2.767152786254883, Accucacy: 15.100000381469727%\n",
      "Iteration: 1500, Loss: 2.7769227027893066, Accucacy: 16.540000915527344%\n",
      "Iteration: 2000, Loss: 2.8201231956481934, Accucacy: 17.260000228881836%\n",
      "Iteration: 2500, Loss: 2.633742570877075, Accucacy: 18.030000686645508%\n",
      "Iteration: 3000, Loss: 2.6524972915649414, Accucacy: 18.049999237060547%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        # 모델이 데이터를 처리하기 위해서는 모델과 데이터가 동일한 장치에 있어야 함\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels) # autograd = 자동미분계산\n",
    "        # Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\n",
    "        # 자동 미분에 대한 값을 저장\n",
    "        \n",
    "        # 해당 과정은 파이토치에서 항상 고정\n",
    "        outputs = model2(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad() # optimizer가 실행되기 전에 초기화 시킴\n",
    "        loss.backward() # 오차 역전파\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50): # = 50으로 나누어 떨어졌을 때\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels, in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model2(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device) # (출력값, 인덱스)[1]\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels) # 전체 정답값 갯수 total에 담기\n",
    "                \n",
    "            accuracy = correct * 100 / total # 정확도 계산\n",
    "            loss_list.append(loss.data) # loss = criterion(outputs, labels)\n",
    "            # 손실값을 50 steps 마다 기록을 남길 것\n",
    "            iteration_list.append(count) # step = iteration\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f\"Iteration: {count}, Loss: {loss.data}, Accucacy: {accuracy}%\")\n",
    "            # 로그 뿌리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9769e0",
   "metadata": {},
   "source": [
    "# 모델 생성3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a38d92",
   "metadata": {},
   "source": [
    "### 심층 신경망 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4e3b3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 28 * 28 = 784\n",
    "        self.fc1 = nn.Linear(in_features = 784, out_features = 256)\n",
    "        self.drop = nn.Dropout2d(0.3)\n",
    "        self.fc2 = nn.Linear(in_features = 256, out_features = 128)\n",
    "        self.fc3 = nn.Linear(in_features = 128, out_features = 10)\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        out = input_data.view(-1, 784)\n",
    "        # 활성화함수는 F.relu()로 forward() 함수에서 정의할 수도 있고\n",
    "        # nn.ReLU()로  __init__() 에서 정의할 수도 있음\n",
    "        out = F.relu(self.fc1(out)) # fc = fully connected 전결합층\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7c666dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist3(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 심층 신경망 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model3 = Mnist3()\n",
    "model3.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr = learning_rate)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e874c",
   "metadata": {},
   "source": [
    "# 모델 학습3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e07073d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.3700803816318512, Accucacy: 90.94000244140625%\n",
      "Iteration: 1000, Loss: 0.2579551041126251, Accucacy: 93.4800033569336%\n",
      "Iteration: 1500, Loss: 0.32196009159088135, Accucacy: 94.54000091552734%\n",
      "Iteration: 2000, Loss: 0.10717396438121796, Accucacy: 95.36000061035156%\n",
      "Iteration: 2500, Loss: 0.06886934489011765, Accucacy: 94.69000244140625%\n",
      "Iteration: 3000, Loss: 0.2008088231086731, Accucacy: 94.93000030517578%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        # 모델이 데이터를 처리하기 위해서는 모델과 데이터가 동일한 장치에 있어야 함\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels) # autograd = 자동미분계산\n",
    "        # Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\n",
    "        # 자동 미분에 대한 값을 저장\n",
    "        \n",
    "        # 해당 과정은 파이토치에서 항상 고정\n",
    "        outputs = model3(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad() # optimizer가 실행되기 전에 초기화 시킴\n",
    "        loss.backward() # 오차 역전파\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50): # = 50으로 나누어 떨어졌을 때\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels, in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model3(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device) # (출력값, 인덱스)[1]\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels) # 전체 정답값 갯수 total에 담기\n",
    "                \n",
    "            accuracy = correct * 100 / total # 정확도 계산\n",
    "            loss_list.append(loss.data) # loss = criterion(outputs, labels)\n",
    "            # 손실값을 50 steps 마다 기록을 남길 것\n",
    "            iteration_list.append(count) # step = iteration\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f\"Iteration: {count}, Loss: {loss.data}, Accucacy: {accuracy}%\")\n",
    "            # 로그 뿌리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787f22e",
   "metadata": {},
   "source": [
    "# 모델 생성4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c335032",
   "metadata": {},
   "source": [
    "### ### 합성곱 신경망 모델 생성2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8652ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels=32, kernel_size=3, padding = 1),\n",
    "            # (28 - 3 + 2 * 1)/1 + 1 =28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            # 28 / 2 = 14\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding = 1),\n",
    "            # (14 - 3 + 2 * 1)/1 + 1 = 14\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            # 14 / 2 = 7\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding = 1),\n",
    "            # (7 - 3 + 2 * 1)/1 + 1 = 7\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            # 7 / 2 = 3.5\n",
    "        )\n",
    "        \n",
    "        # 전결합층\n",
    "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=1024) \n",
    "        # out_features = 유닛 수\n",
    "        self.drop = nn.Dropout2d(0.3)\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=10)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "990dc691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist4(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=3136, out_features=1024, bias=True)\n",
      "  (drop): Dropout2d(p=0.3, inplace=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 심층 신경망 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model4 = Mnist4()\n",
    "model4.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model4.parameters(), lr = learning_rate)\n",
    "print(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef785d43",
   "metadata": {},
   "source": [
    "# 모델 학습4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2bf534d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x1152 and 3136x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 21\u001b[0m\n\u001b[0;32m     16\u001b[0m labels \u001b[38;5;241m=\u001b[39m Variable(labels) \u001b[38;5;66;03m# autograd = 자동미분계산\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 자동 미분에 대한 값을 저장\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 해당 과정은 파이토치에서 항상 고정\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model4(train)\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# optimizer가 실행되기 전에 초기화 시킴\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[178], line 40\u001b[0m, in \u001b[0;36mMnist4.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(out)\n\u001b[0;32m     39\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# Flatten\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(out)\n\u001b[0;32m     41\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(out)\n\u001b[0;32m     42\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(out)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x1152 and 3136x1024)"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        # 모델이 데이터를 처리하기 위해서는 모델과 데이터가 동일한 장치에 있어야 함\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels) # autograd = 자동미분계산\n",
    "        # Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\n",
    "        # 자동 미분에 대한 값을 저장\n",
    "        \n",
    "        # 해당 과정은 파이토치에서 항상 고정\n",
    "        outputs = model4(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad() # optimizer가 실행되기 전에 초기화 시킴\n",
    "        loss.backward() # 오차 역전파\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50): # = 50으로 나누어 떨어졌을 때\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels, in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model4(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device) # (출력값, 인덱스)[1]\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels) # 전체 정답값 갯수 total에 담기\n",
    "                \n",
    "            accuracy = correct * 100 / total # 정확도 계산\n",
    "            loss_list.append(loss.data) # loss = criterion(outputs, labels)\n",
    "            # 손실값을 50 steps 마다 기록을 남길 것\n",
    "            iteration_list.append(count) # step = iteration\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f\"Iteration: {count}, Loss: {loss.data}, Accucacy: {accuracy}%\")\n",
    "            # 로그 뿌리기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8292e",
   "metadata": {},
   "source": [
    "# 모델 생성5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "65c82660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels=32, kernel_size=3, padding = 1),\n",
    "            # (28 - 3 + 2 * 1)/1 + 1 =28\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            # 28 / 2 = 14\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding = 1),\n",
    "            # (14 - 3 + 2 * 1)/1 + 1 = 14\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(2)\n",
    "            # 14 / 2 = 7\n",
    "        )\n",
    "        \n",
    "        # 전결합층\n",
    "        self.fc1 = nn.Linear(in_features=64*7*7, out_features=10) \n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) # Flatten\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8eadb5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist5(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=3136, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 심층 신경망 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model5 = Mnist5()\n",
    "model5.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model5.parameters(), lr = learning_rate)\n",
    "print(model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdd351",
   "metadata": {},
   "source": [
    "# 모델 학습5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6d7adcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.10147961974143982, Accucacy: 98.12000274658203%\n",
      "Iteration: 1000, Loss: 0.04126359149813652, Accucacy: 98.25%\n",
      "Iteration: 1500, Loss: 0.039959847927093506, Accucacy: 98.6500015258789%\n",
      "Iteration: 2000, Loss: 0.01594449020922184, Accucacy: 98.6500015258789%\n",
      "Iteration: 2500, Loss: 0.005076043773442507, Accucacy: 98.80999755859375%\n",
      "Iteration: 3000, Loss: 0.19605380296707153, Accucacy: 98.62999725341797%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device),labels.to(device)\n",
    "        # 모델이 데이터를 처리하기 위해서는 모델과 데이터가 동일한 장치에 있어야 함\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28))\n",
    "        labels = Variable(labels) # autograd = 자동미분계산\n",
    "        # Autograd는 자동 미분을 수행하는 파이토치의 핵심 패키지\n",
    "        # 자동 미분에 대한 값을 저장\n",
    "        \n",
    "        # 해당 과정은 파이토치에서 항상 고정\n",
    "        outputs = model5(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad() # optimizer가 실행되기 전에 초기화 시킴\n",
    "        loss.backward() # 오차 역전파\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50): # = 50으로 나누어 떨어졌을 때\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels, in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                \n",
    "                test = Variable(images.view(100, 1, 28, 28))\n",
    "                outputs = model5(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device) # (출력값, 인덱스)[1]\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels) # 전체 정답값 갯수 total에 담기\n",
    "                \n",
    "            accuracy = correct * 100 / total # 정확도 계산\n",
    "            loss_list.append(loss.data) # loss = criterion(outputs, labels)\n",
    "            # 손실값을 50 steps 마다 기록을 남길 것\n",
    "            iteration_list.append(count) # step = iteration\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(f\"Iteration: {count}, Loss: {loss.data}, Accucacy: {accuracy}%\")\n",
    "            # 로그 뿌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ae60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c287a3c4",
   "metadata": {},
   "source": [
    "# 풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "92fc0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2b38437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9bd347bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 텐서로 변경\n",
    "trasform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "9f503786",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST(\n",
    "    root = \"./data/\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = trasform)\n",
    "testset = datasets.MNIST(\n",
    "    root = \"./data/\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = trasform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bfabaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ed236d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 공급 객체 선언\n",
    "train_loader = data.DataLoader(\n",
    "    dataset = trainset,\n",
    "    batch_size = batch_size)\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    dataset = testset,\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9269f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''모델 구조 정의'''\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 입력 데이터 = x\n",
    "        # x.shape([배치사이즈, 채널, 높이, 너비])\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        \n",
    "        # x.shape([배치사이즈, 784])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # x.shape([배치사이즈, 앞 레이어의 출력 개수])\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0197997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 객체 선언\n",
    "model = Net().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ffa4da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b7ec5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수 정의\n",
    "def train(model, train_loader, optimizer):\n",
    "    # 모델을 학습 모드로 전환\n",
    "    model.train()\n",
    "     \n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # 하나의 batch = step\n",
    "        # 학습 데이터를 DEVICE로 보냄\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        \n",
    "        # 매 이레테이션 마다 기울기를 계산하기 위해 zero_grad() 호출\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 실제 모델의 예측값 받아오기\n",
    "        output = model(data)\n",
    "        \n",
    "        # 정답 데이터와의 cross entropy Loss 계산\n",
    "        # Loss는 mini batch의 클래스의 오차 평균값\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # 기울기 계산\n",
    "        loss.backward()\n",
    "        \n",
    "        # 가중치 수정\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ea1aa8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    # 모델을 평가모드로 전환\n",
    "    model.eval()\n",
    "    \n",
    "    # 필요한 변수 초기화\n",
    "    # test 과정에서의 Loss\n",
    "    # 실제 모델의 예측이 정답과 맞은 횟수(correct)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 평가 시에는 기울기를 계산하지 않으므로, no_grad를 명시\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "        \n",
    "            # 모든 오차 계산하기\n",
    "            test_loss += F.cross_entropy(output, target, reduction = \"sum\").item()\n",
    "            # output과 target값을 넣고 오차 계산\n",
    "            # reduction: str = 'mean'! 기본값은 평균(mean)\n",
    "            \n",
    "            # 가장 큰 값을 가진 클래스가 모델의 예측\n",
    "            # 예측과 정답을 비교하여 일치하면 correct에 1 더하기\n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            # output.max = arrgmax 역할도 함! 최댓값의 인덱스도 같이 찾아줌!\n",
    "            \n",
    "            # eq() : 값이 일치하면 1, 아니면 0\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # target.view_as(pred) = target모양을 pred의 모양새와 맞춰주는 것\n",
    "        \n",
    "        test_loss /= len(test_loader.dataset) # /= : 나누고 할당행\n",
    "        # -> reduction = \"sum\"을 했기 때문에!\n",
    "        # 로스를 묶어서 평균을 내었음 -> 근데 우리는 reduction에서 sum을 해서 loss 계산이 총합이 되었음 (총 개수)\n",
    "        # 그래서 나눌 필요가 있음!\n",
    "        \n",
    "        # 정확도 계산\n",
    "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
    "        \n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "74b549cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss : 0.4105, Accuracy : 88.85%\n",
      "[2] Test Loss : 0.3261, Accuracy : 90.67%\n",
      "[3] Test Loss : 0.2924, Accuracy : 91.81%\n",
      "[4] Test Loss : 0.2703, Accuracy : 92.41%\n",
      "[5] Test Loss : 0.2529, Accuracy : 92.92%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print(f\"[{epoch}] Test Loss : {test_loss:.4f}, Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920036d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e584c4f2",
   "metadata": {},
   "source": [
    "### 모델5 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f63fd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model5, test_loader):\n",
    "    # 모델을 평가모드로 전환\n",
    "    model5.eval()\n",
    "    \n",
    "    # 필요한 변수 초기화\n",
    "    # test 과정에서의 Loss\n",
    "    # 실제 모델의 예측이 정답과 맞은 횟수(correct)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad(): # 평가 시에는 기울기를 계산하지 않으므로, no_grad를 명시\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model5(data)\n",
    "        \n",
    "            # 모든 오차 계산하기\n",
    "            test_loss += F.cross_entropy(output, target, reduction = \"sum\").item()\n",
    "            # output과 target값을 넣고 오차 계산\n",
    "            # reduction: str = 'mean'! 기본값은 평균(mean)\n",
    "            \n",
    "            # 가장 큰 값을 가진 클래스가 모델의 예측\n",
    "            # 예측과 정답을 비교하여 일치하면 correct에 1 더하기\n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            # output.max = arrgmax 역할도 함! 최댓값의 인덱스도 같이 찾아줌!\n",
    "            \n",
    "            # eq() : 값이 일치하면 1, 아니면 0\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # target.view_as(pred) = target모양을 pred의 모양새와 맞춰주는 것\n",
    "        \n",
    "        test_loss /= len(test_loader.dataset) # /= : 나누고 할당행\n",
    "        # -> reduction = \"sum\"을 했기 때문에!\n",
    "        # 로스를 묶어서 평균을 내었음 -> 근데 우리는 reduction에서 sum을 해서 loss 계산이 총합이 되었음 (총 개수)\n",
    "        # 그래서 나눌 필요가 있음!\n",
    "        \n",
    "        # 정확도 계산\n",
    "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
    "        \n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d61d6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss : 0.2330, Accuracy : 93.39%\n",
      "[2] Test Loss : 0.2330, Accuracy : 93.39%\n",
      "[3] Test Loss : 0.2330, Accuracy : 93.39%\n",
      "[4] Test Loss : 0.2330, Accuracy : 93.39%\n",
      "[5] Test Loss : 0.2330, Accuracy : 93.39%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(model5, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model5, test_loader)\n",
    "    \n",
    "    print(f\"[{epoch}] Test Loss : {test_loss:.4f}, Accuracy : {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695137c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
